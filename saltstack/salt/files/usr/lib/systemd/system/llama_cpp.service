[Unit]
Description=llama.cpp
After=network.target
StartLimitIntervalSec=0

[Service]
User={{ pillar['shellserver_unprivileged_user_name'] }}
Type=simple
Restart=always
RestartSec=10
WorkingDirectory=/etc/llama.cpp
ExecStart=/bin/bash -c "test -d /mnt/storage/models && build/bin/llama-server -m $(find /mnt/storage/models/ -name '*.gguf' | head -n 1) -t $(nproc) --port 8080 --host 192.168.1.235 --flash-attn on --cache-type-k q4_0 --cache-type-v q4_0 -c 128000 --jinja"

[Install]
WantedBy=multi-user.target
